{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec41df5-fa96-4e78-a362-7f30bfd95916",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 518) (1502553532.py, line 518)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 518\u001b[1;36m\u001b[0m\n\u001b[1;33m    processed_df['customer_decline_7_15'] = processed_df['unique_customers_last_7_days'] - processed_df['unique_customers_last_15_day\u001b[0m\n\u001b[1;37m                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 518)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INSURANCE AGENT PERFORMANCE PREDICTION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train_storming_round.csv')\n",
    "test_data = pd.read_csv('test_storming_round.csv')\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "#############################################\n",
    "# PART 1: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "#############################################\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Convert date columns to datetime format for both train and test\n",
    "date_columns = ['agent_join_month', 'first_policy_sold_month', 'year_month']\n",
    "for col in date_columns:\n",
    "    train_data[col] = pd.to_datetime(train_data[col])\n",
    "    test_data[col] = pd.to_datetime(test_data[col])\n",
    "\n",
    "# 1. Summary statistics of the dataset\n",
    "print(\"\\n1. SUMMARY STATISTICS\")\n",
    "print(\"-\"*30)\n",
    "summary_stats = train_data.describe().T\n",
    "print(summary_stats)\n",
    "\n",
    "# 2. Missing values analysis\n",
    "print(\"\\n2. MISSING VALUES ANALYSIS\")\n",
    "print(\"-\"*30)\n",
    "missing_train = train_data.isnull().sum()\n",
    "print(\"Missing values in training data:\")\n",
    "print(missing_train[missing_train > 0])\n",
    "\n",
    "# 3. Create target column: if new_policy_count is 0, target = 0, else target = 1\n",
    "# (Need to create this first for EDA by target)\n",
    "target = np.where(train_data['new_policy_count'] == 0, 0, 1)\n",
    "train_data['target'] = target\n",
    "\n",
    "print(\"\\n3. TARGET DISTRIBUTION\")\n",
    "print(\"-\"*30)\n",
    "target_counts = train_data['target'].value_counts()\n",
    "print(f\"Target distribution:\\n{target_counts}\")\n",
    "print(f\"Target percentage:\\n{target_counts / len(train_data) * 100}\")\n",
    "\n",
    "# 4. Time Series Analysis - Sales patterns by month\n",
    "print(\"\\n4. TIME SERIES ANALYSIS\")\n",
    "print(\"-\"*30)\n",
    "monthly_sales = train_data.groupby('year_month')['new_policy_count'].sum().reset_index()\n",
    "monthly_avg_sales = train_data.groupby('year_month')['new_policy_count'].mean().reset_index()\n",
    "monthly_nill_agents = train_data.groupby('year_month')['target'].value_counts().unstack().fillna(0).reset_index()\n",
    "\n",
    "print(\"Monthly total sales:\")\n",
    "print(monthly_sales.head())\n",
    "print(\"\\nMonthly average sales per agent:\")\n",
    "print(monthly_avg_sales.head())\n",
    "print(\"\\nMonthly NILL vs Non-NILL agents:\")\n",
    "if 0 in monthly_nill_agents.columns and 1 in monthly_nill_agents.columns:\n",
    "    print(monthly_nill_agents.head())\n",
    "else:\n",
    "    print(\"Could not calculate NILL vs Non-NILL by month due to data structure\")\n",
    "\n",
    "# Plot monthly sales trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_sales['year_month'], monthly_sales['new_policy_count'], marker='o', linestyle='-')\n",
    "plt.title('Total Policy Sales by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Policies Sold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('monthly_sales_trend.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. Agent Experience Analysis\n",
    "print(\"\\n5. AGENT EXPERIENCE ANALYSIS\")\n",
    "print(\"-\"*30)\n",
    "train_data['agent_experience_months'] = ((train_data['year_month'].dt.year - train_data['agent_join_month'].dt.year) * 12 + \n",
    "                                (train_data['year_month'].dt.month - train_data['agent_join_month'].dt.month))\n",
    "\n",
    "# Calculate months since first policy sold\n",
    "train_data['months_since_first_policy'] = np.where(pd.notnull(train_data['first_policy_sold_month']),\n",
    "                                         ((train_data['year_month'].dt.year - train_data['first_policy_sold_month'].dt.year) * 12 + \n",
    "                                         (train_data['year_month'].dt.month - train_data['first_policy_sold_month'].dt.month)),\n",
    "                                         -1)  # -1 for agents who haven't sold a policy yet\n",
    "\n",
    "print(\"Agent experience distribution:\")\n",
    "print(train_data['agent_experience_months'].describe())\n",
    "\n",
    "# Group performance by experience\n",
    "exp_performance = train_data.groupby('agent_experience_months')['new_policy_count'].agg(['mean', 'median', 'count']).reset_index()\n",
    "print(\"\\nPerformance by experience months (first 10 rows):\")\n",
    "print(exp_performance.head(10))\n",
    "\n",
    "# Plot agent performance by experience\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(exp_performance['agent_experience_months'], exp_performance['mean'], alpha=0.7)\n",
    "plt.title('Average Policy Sales by Agent Experience')\n",
    "plt.xlabel('Months of Experience')\n",
    "plt.ylabel('Average Policies Sold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sales_by_experience.png')\n",
    "plt.close()\n",
    "\n",
    "# 6. Agent trajectory over time\n",
    "print(\"\\n6. AGENT TRAJECTORIES\")\n",
    "print(\"-\"*30)\n",
    "# Select a sample of agents to visualize their trajectories\n",
    "sample_agents = train_data['agent_code'].unique()[:5]\n",
    "agent_trajectories = train_data[train_data['agent_code'].isin(sample_agents)]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "for agent in sample_agents:\n",
    "    agent_data = train_data[train_data['agent_code'] == agent]\n",
    "    plt.plot(agent_data['year_month'], agent_data['new_policy_count'], marker='o', label=f'Agent {agent}')\n",
    "\n",
    "plt.title('Policy Sales Trajectories for Sample Agents')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Policies Sold')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('agent_trajectories.png')\n",
    "plt.close()\n",
    "\n",
    "# 7. Correlation Analysis\n",
    "print(\"\\n7. CORRELATION ANALYSIS\")\n",
    "print(\"-\"*30)\n",
    "numeric_cols = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation = train_data[numeric_cols].corr()\n",
    "\n",
    "# Print correlations with target\n",
    "target_corr = correlation['target'].sort_values(ascending=False)\n",
    "print(\"Features correlation with target (top 10):\")\n",
    "print(target_corr.head(10))\n",
    "\n",
    "# Plot correlation heatmap of important features\n",
    "plt.figure(figsize=(14, 12))\n",
    "top_features = target_corr.index[:15]  # Top 15 correlated features\n",
    "sns.heatmap(train_data[top_features].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Top Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# 8. Feature distributions by target\n",
    "print(\"\\n8. FEATURE DISTRIBUTIONS BY TARGET\")\n",
    "print(\"-\"*30)\n",
    "important_features = ['new_policy_count', 'unique_customers', 'unique_quotations', \n",
    "                      'unique_proposal', 'agent_experience_months', 'agent_age']\n",
    "\n",
    "for feature in important_features[:3]:  # Show first 3 for brevity\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=train_data, x=feature, hue='target', bins=30, kde=True, element='step')\n",
    "    plt.title(f'Distribution of {feature} by Target')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{feature}_by_target.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Summary of {feature} by target:\")\n",
    "    print(train_data.groupby('target')[feature].describe())\n",
    "\n",
    "# 9. Funnel Analysis\n",
    "print(\"\\n9. FUNNEL ANALYSIS\")\n",
    "print(\"-\"*30)\n",
    "funnel_avg = train_data[['unique_proposal', 'unique_quotations', 'unique_customers', 'new_policy_count']].mean()\n",
    "print(\"Average funnel metrics:\")\n",
    "print(funnel_avg)\n",
    "\n",
    "# Calculate conversion rates\n",
    "train_data['proposal_to_quotation_rate'] = train_data['unique_quotations'] / train_data['unique_proposal'].replace(0, np.nan)\n",
    "train_data['quotation_to_customer_rate'] = train_data['unique_customers'] / train_data['unique_quotations'].replace(0, np.nan)\n",
    "train_data['customer_to_policy_rate'] = train_data['new_policy_count'] / train_data['unique_customers'].replace(0, np.nan)\n",
    "\n",
    "print(\"\\nConversion rates by target:\")\n",
    "conversion_by_target = train_data.groupby('target')[['proposal_to_quotation_rate', 'quotation_to_customer_rate', 'customer_to_policy_rate']].mean()\n",
    "print(conversion_by_target)\n",
    "\n",
    "# 10. Recent Activity vs. Overall Activity\n",
    "print(\"\\n10. RECENT VS OVERALL ACTIVITY\")\n",
    "print(\"-\"*30)\n",
    "recent_cols = ['unique_proposals_last_7_days', 'unique_quotations_last_7_days', 'unique_customers_last_7_days']\n",
    "overall_cols = ['unique_proposal', 'unique_quotations', 'unique_customers']\n",
    "\n",
    "for recent, overall in zip(recent_cols, overall_cols):\n",
    "    train_data[f'{recent}_ratio'] = train_data[recent] / train_data[overall].replace(0, np.nan)\n",
    "    print(f\"Average {recent}_ratio: {train_data[f'{recent}_ratio'].mean()}\")\n",
    "\n",
    "print(\"\\nRecent activity ratios by target:\")\n",
    "recent_ratio_cols = [col for col in train_data.columns if '_ratio' in col]\n",
    "print(train_data.groupby('target')[recent_ratio_cols].mean())\n",
    "\n",
    "# 11. Agent Segmentation by Performance\n",
    "print(\"\\n11. AGENT PERFORMANCE SEGMENTATION\")\n",
    "print(\"-\"*30)\n",
    "# Create a new column for agent performance category\n",
    "agent_avg_performance = train_data.groupby('agent_code')['new_policy_count'].mean()\n",
    "performance_quantiles = agent_avg_performance.quantile([0.33, 0.67])\n",
    "\n",
    "low_performers = agent_avg_performance[agent_avg_performance <= performance_quantiles[0.33]].index\n",
    "medium_performers = agent_avg_performance[(agent_avg_performance > performance_quantiles[0.33]) & \n",
    "                                         (agent_avg_performance <= performance_quantiles[0.67])].index\n",
    "high_performers = agent_avg_performance[agent_avg_performance > performance_quantiles[0.67]].index\n",
    "\n",
    "print(f\"Number of low performers: {len(low_performers)}\")\n",
    "print(f\"Number of medium performers: {len(medium_performers)}\")\n",
    "print(f\"Number of high performers: {len(high_performers)}\")\n",
    "\n",
    "# Add performance category to the dataset\n",
    "train_data['performance_category'] = 'medium'\n",
    "train_data.loc[train_data['agent_code'].isin(low_performers), 'performance_category'] = 'low'\n",
    "train_data.loc[train_data['agent_code'].isin(high_performers), 'performance_category'] = 'high'\n",
    "\n",
    "# Calculate NILL rate by performance category\n",
    "nill_by_category = train_data.groupby('performance_category')['target'].mean()\n",
    "print(\"\\nProbability of non-NILL by performance category:\")\n",
    "print(nill_by_category)\n",
    "\n",
    "#############################################\n",
    "# PART 2: FEATURE ENGINEERING\n",
    "#############################################\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def create_target(df):\n",
    "    \"\"\"Create target column: if new_policy_count is 0, target = 0, else target = 1\"\"\"\n",
    "    if 'new_policy_count' in df.columns:\n",
    "        return np.where(df['new_policy_count'] == 0, 0, 1)\n",
    "    return None\n",
    "\n",
    "# Create target for training data only\n",
    "target = create_target(train_data)\n",
    "\n",
    "def feature_engineering(df, is_training=True):\n",
    "    \"\"\"Comprehensive feature engineering function\"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Convert date columns to datetime format if they're not already\n",
    "    date_columns = ['agent_join_month', 'first_policy_sold_month', 'year_month']\n",
    "    for col in date_columns:\n",
    "        if col in processed_df.columns and not pd.api.types.is_datetime64_any_dtype(processed_df[col]):\n",
    "            processed_df[col] = pd.to_datetime(processed_df[col])\n",
    "    \n",
    "    # 1. Time-based features\n",
    "    processed_df['agent_experience_months'] = ((processed_df['year_month'].dt.year - processed_df['agent_join_month'].dt.year) * 12 + \n",
    "                                    (processed_df['year_month'].dt.month - processed_df['agent_join_month'].dt.month))\n",
    "    \n",
    "    processed_df['months_since_first_policy'] = np.where(pd.notnull(processed_df['first_policy_sold_month']),\n",
    "                                             ((processed_df['year_month'].dt.year - processed_df['first_policy_sold_month'].dt.year) * 12 + \n",
    "                                             (processed_df['year_month'].dt.month - processed_df['first_policy_sold_month'].dt.month)),\n",
    "                                             -1)  # -1 for agents who haven't sold a policy yet\n",
    "    \n",
    "    # Extract date components\n",
    "    processed_df['current_month'] = processed_df['year_month'].dt.month\n",
    "    processed_df['current_year'] = processed_df['year_month'].dt.year\n",
    "    processed_df['join_month'] = processed_df['agent_join_month'].dt.month\n",
    "    processed_df['join_year'] = processed_df['agent_join_month'].dt.year\n",
    "    processed_df['is_q4'] = processed_df['current_month'].isin([10, 11, 12]).astype(int)  # Q4 often has different sales patterns\n",
    "    processed_df['is_q1'] = processed_df['current_month'].isin([1, 2, 3]).astype(int)\n",
    "    \n",
    "    # 2. Funnel conversion features\n",
    "    processed_df['proposal_to_quotation_ratio'] = processed_df['unique_quotations'] / (processed_df['unique_proposal'] + 1)\n",
    "    processed_df['quotation_to_customer_ratio'] = processed_df['unique_customers'] / (processed_df['unique_quotations'] + 1)\n",
    "    processed_df['proposal_to_customer_ratio'] = processed_df['unique_customers'] / (processed_df['unique_proposal'] + 1)\n",
    "    \n",
    "    # 3. Activity trend features - Calculate slopes of activity\n",
    "    processed_df['proposal_trend_1'] = processed_df['unique_proposals_last_7_days'] - processed_df['unique_proposals_last_15_days']\n",
    "    processed_df['proposal_trend_2'] = processed_df['unique_proposals_last_15_days'] - processed_df['unique_proposals_last_21_days']\n",
    "    processed_df['quotation_trend_1'] = processed_df['unique_quotations_last_7_days'] - processed_df['unique_quotations_last_15_days']\n",
    "    processed_df['quotation_trend_2'] = processed_df['unique_quotations_last_15_days'] - processed_df['unique_quotations_last_21_days']\n",
    "    processed_df['customer_trend_1'] = processed_df['unique_customers_last_7_days'] - processed_df['unique_customers_last_15_days']\n",
    "    processed_df['customer_trend_2'] = processed_df['unique_customers_last_15_days'] - processed_df['unique_customers_last_21_days']\n",
    "    \n",
    "    # 4. Activity acceleration (second derivative)\n",
    "    processed_df['proposal_acceleration'] = processed_df['proposal_trend_1'] - processed_df['proposal_trend_2']\n",
    "    processed_df['quotation_acceleration'] = processed_df['quotation_trend_1'] - processed_df['quotation_trend_2']\n",
    "    processed_df['customer_acceleration'] = processed_df['customer_trend_1'] - processed_df['customer_trend_2']\n",
    "    \n",
    "    # 5. Recent activity ratio features\n",
    "    processed_df['recent_proposal_ratio'] = processed_df['unique_proposals_last_7_days'] / (processed_df['unique_proposal'] + 1)\n",
    "    processed_df['recent_quotation_ratio'] = processed_df['unique_quotations_last_7_days'] / (processed_df['unique_quotations'] + 1)\n",
    "    processed_df['recent_customer_ratio'] = processed_df['unique_customers_last_7_days'] / (processed_df['unique_customers'] + 1)\n",
    "    \n",
    "    # 6. Policy quality metrics\n",
    "    if 'ANBP_value' in processed_df.columns and 'new_policy_count' in processed_df.columns:\n",
    "        processed_df['avg_policy_value'] = processed_df['ANBP_value'] / (processed_df['new_policy_count'] + 0.1)\n",
    "    \n",
    "    if 'net_income' in processed_df.columns and 'new_policy_count' in processed_df.columns:\n",
    "        processed_df['avg_policy_income'] = processed_df['net_income'] / (processed_df['new_policy_count'] + 0.1)\n",
    "    \n",
    "    # 7. Payment method preference\n",
    "    if 'number_of_policy_holders' in processed_df.columns and 'number_of_cash_payment_policies' in processed_df.columns:\n",
    "        processed_df['cash_payment_ratio'] = processed_df['number_of_cash_payment_policies'] / (processed_df['number_of_policy_holders'] + 1)\n",
    "    \n",
    "    # 8. Experience-adjusted performance\n",
    "    # How does this agent compare to others with similar experience?\n",
    "    if is_training and 'new_policy_count' in processed_df.columns:\n",
    "        # Only create these features for training since they require statistics from the entire dataset\n",
    "        exp_avg = processed_df.groupby('agent_experience_months')['new_policy_count'].transform('mean')\n",
    "        processed_df['performance_vs_experience_peers'] = processed_df['new_policy_count'] / (exp_avg + 0.1)\n",
    "    \n",
    "    # 9. Activity consistency metrics\n",
    "    processed_df['proposal_consistency'] = processed_df['unique_proposal'] / (processed_df['unique_proposals_last_7_days'] * 3 + 0.1)\n",
    "    processed_df['quotation_consistency'] = processed_df['unique_quotations'] / (processed_df['unique_quotations_last_7_days'] * 3 + 0.1)\n",
    "    processed_df['customer_consistency'] = processed_df['unique_customers'] / (processed_df['unique_customers_last_7_days'] * 3 + 0.1)\n",
    "    \n",
    "    # 10. Combined features\n",
    "    processed_df['activity_score'] = (processed_df['unique_proposal'] + \n",
    "                                    processed_df['unique_quotations'] * 2 + \n",
    "                                    processed_df['unique_customers'] * 3)\n",
    "    \n",
    "    processed_df['recent_activity_score'] = (processed_df['unique_proposals_last_7_days'] + \n",
    "                                           processed_df['unique_quotations_last_7_days'] * 2 + \n",
    "                                           processed_df['unique_customers_last_7_days'] * 3)\n",
    "    \n",
    "    processed_df['activity_trend_score'] = (processed_df['proposal_trend_1'] + \n",
    "                                          processed_df['quotation_trend_1'] * 2 + \n",
    "                                          processed_df['customer_trend_1'] * 3)\n",
    "    \n",
    "    # 11. Squared features for non-linear relationships\n",
    "    processed_df['agent_age_squared'] = processed_df['agent_age'] ** 2\n",
    "    processed_df['experience_squared'] = processed_df['agent_experience_months'] ** 2\n",
    "    \n",
    "    # 12. Interaction features\n",
    "    processed_df['age_experience_interaction'] = processed_df['agent_age'] * processed_df['agent_experience_months']\n",
    "    processed_df['proposal_quotation_interaction'] = processed_df['unique_proposal'] * processed_df['unique_quotations']\n",
    "    \n",
    "    # Drop original date columns\n",
    "    drop_cols = ['agent_join_month', 'first_policy_sold_month', 'year_month']\n",
    "    \n",
    "    # Remove new_policy_count to prevent target leakage\n",
    "    if 'new_policy_count' in processed_df.columns and not is_training:\n",
    "        drop_cols.append('new_policy_count')\n",
    "    \n",
    "    processed_df = processed_df.drop(columns=drop_cols, errors='ignore')\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Apply feature engineering to train and test data\n",
    "print(\"Applying feature engineering...\")\n",
    "train_processed = feature_engineering(train_data)\n",
    "test_processed = feature_engineering(test_data, is_training=False)\n",
    "\n",
    "# Check engineered feature set\n",
    "print(f\"\\nNumber of features after engineering: {train_processed.shape[1]}\")\n",
    "print(\"Sample of engineered features:\")\n",
    "print(train_processed.columns.tolist()[:10])\n",
    "\n",
    "#############################################\n",
    "# PART 3: MODEL TRAINING AND EVALUATION\n",
    "#############################################\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL TRAINING AND EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define features and target\n",
    "X = train_processed.drop(['row_id', 'agent_code', 'target', 'new_policy_count', 'performance_category'], axis=1, errors='ignore')\n",
    "y = target\n",
    "\n",
    "# Check for any remaining missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"\\nHandling remaining missing values...\")\n",
    "    X = X.fillna(X.median())\n",
    "\n",
    "# Split data for training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling - Use RobustScaler to handle outliers better\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "print(f\"\\nTrain features shape: {X_train_scaled.shape}\")\n",
    "print(f\"Validation features shape: {X_valid_scaled.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize multiple models for comparison\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        gamma=0.1,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1,\n",
    "        scale_pos_weight=1,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        objective='binary',\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Evaluate each model with cross-validation\n",
    "print(\"\\nModel cross-validation results:\")\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='f1')\n",
    "    cv_results[name] = cv_scores\n",
    "    print(f\"{name} - F1 Score: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    # Train the model on the full training set\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_valid_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_valid_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    precision = precision_score(y_valid, y_pred)\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred_proba)\n",
    "    \n",
    "    print(f\"Validation Metrics for {name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Select the best model based on cross-validation F1 score\n",
    "best_model_name = max(cv_results, key=lambda k: cv_results[k].mean())\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with average F1 score: {cv_results[best_model_name].mean():.4f}\")\n",
    "\n",
    "# Create an ensemble model (voting classifier)\n",
    "print(\"\\nCreating ensemble model...\")\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', models['XGBoost']),\n",
    "        ('lgbm', models['LightGBM']),\n",
    "        ('rf', models['RandomForest']),\n",
    "        ('gb', models['GradientBoosting'])\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[2, 2, 1, 1]  # Weighting based on individual performance\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_pred = ensemble_model.predict(X_valid_scaled)\n",
    "ensemble_pred_proba = ensemble_model.predict_proba(X_valid_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics for ensemble\n",
    "ensemble_accuracy = accuracy_score(y_valid, ensemble_pred)\n",
    "ensemble_precision = precision_score(y_valid, ensemble_pred)\n",
    "ensemble_recall = recall_score(y_valid, ensemble_pred)\n",
    "ensemble_f1 = f1_score(y_valid, ensemble_pred)\n",
    "ensemble_roc_auc = roc_auc_score(y_valid, ensemble_pred_proba)\n",
    "\n",
    "print(\"\\nEnsemble Model Evaluation:\")\n",
    "print(f\"Accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Precision: {ensemble_precision:.4f}\")\n",
    "print(f\"Recall: {ensemble_recall:.4f}\")\n",
    "print(f\"F1 Score: {ensemble_f1:.4f}\")\n",
    "print(f\"ROC AUC: {ensemble_roc_auc:.4f}\")\n",
    "\n",
    "# Classification report for ensemble\n",
    "print(\"\\nClassification Report (Ensemble):\")\n",
    "print(classification_report(y_valid, ensemble_pred))\n",
    "\n",
    "# Plot confusion matrix for ensemble\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_valid, ensemble_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Ensemble Model)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.savefig('ensemble_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot ROC curve for ensemble\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr, tpr, _ = roc_curve(y_valid, ensemble_pred_proba)\n",
    "plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {ensemble_roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (Ensemble Model)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ensemble_roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot precision-recall curve for ensemble\n",
    "plt.figure(figsize=(8, 6))\n",
    "precision, recall, _ = precision_recall_curve(y_valid, ensemble_pred_proba)\n",
    "avg_precision = average_precision_score(y_valid, ensemble_pred_proba)\n",
    "plt.plot(recall, precision, lw=2, label=f'PR curve (AP = {avg_precision:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (Ensemble Model)')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('ensemble_pr_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature importance analysis (using XGBoost as reference)\n",
    "xgb_model = models['XGBoost']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "plt.title('XGBoost Feature Importance (Top 20)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "#############################################\n",
    "# PART 4: THRESHOLD OPTIMIZATION\n",
    "#############################################\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Find the optimal threshold based on F1 score\n",
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (ensemble_pred_proba >= threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_valid, y_pred_thresh))\n",
    "    precision_scores.append(precision_score(y_valid, y_pred_thresh))\n",
    "    recall_scores.append(recall_score(y_valid, y_pred_thresh))\n",
    "\n",
    "# Find threshold with best F1 score\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "print(f\"Optimal threshold: {best_threshold:.2f} with F1 score: {best_f1:.4f}\")\n",
    "print(f\"At this threshold - Precision: {precision_scores[best_idx]:.4f}, Recall: {recall_scores[best_idx]:.4f}\")\n",
    "\n",
    "# Plot threshold optimization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, f1_scores, 'o-', label='F1 Score')\n",
    "plt.plot(thresholds, precision_scores, 'o-', label='Precision')\n",
    "plt.plot(thresholds, recall_scores, 'o-', label='Recall')\n",
    "plt.axvline(x=best_threshold, color='r', linestyle='--', label=f'Best Threshold: {best_threshold:.2f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Metrics vs. Classification Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('threshold_optimization.png')\n",
    "plt.close()\n",
    "\n",
    "#############################################\n",
    "# PART 5: FINAL PREDICTIONS AND SUBMISSION\n",
    "#############################################\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GENERATING FINAL PREDICTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Prepare test data for prediction\n",
    "X_test = test_processed.drop(['row_id', 'agent_code'], axis=1, errors='ignore')\n",
    "\n",
    "# Handle missing values in test data\n",
    "if X_test.isnull().sum().sum() > 0:\n",
    "    print(\"Handling missing values in test data...\")\n",
    "    X_test = X_test.fillna(X_test.median())\n",
    "\n",
    "# Transform test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make final predictions using the ensemble model\n",
    "test_pred_proba = ensemble_model.predict_proba(X_test_scaled)[:, 1]\n",
    "test_pred = (test_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': test_data['row_id'],\n",
    "    'target_column': test_pred\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('submission3.csv', index=False)\n",
    "print(\"\\nFinal submission file created: submission3.csv\")\n",
    "print(f\"Distribution of predictions: {pd.Series(test_pred).value_counts()}\")\n",
    "\n",
    "#############################################\n",
    "# PART 6: AGENT INSIGHTS AND RECOMMENDATIONS\n",
    "#############################################\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"AGENT INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Identify agents at risk of becoming NILL\n",
    "if ensemble_pred_proba is not None:\n",
    "    # Create a DataFrame with agent codes and their NILL probabilities\n",
    "    agent_risk = pd.DataFrame({\n",
    "        'agent_code': train_data.loc[X_valid.index, 'agent_code'],\n",
    "        'nill_probability': 1 - ensemble_pred_proba,  # Probability of being NILL\n",
    "        'actual_target': y_valid,\n",
    "        'predicted_target': ensemble_pred\n",
    "    })\n",
    "    \n",
    "    # Sort by risk (highest NILL probability first)\n",
    "    high_risk_agents = agent_risk.sort_values('nill_probability', ascending=False).head(10)\n",
    "    \n",
    "    print(\"\\nTop 10 Agents at Highest Risk of Becoming NILL:\")\n",
    "    print(high_risk_agents)\n",
    "    \n",
    "    # Group high-risk agents and analyze their characteristics\n",
    "    high_risk_indices = agent_risk[agent_risk['nill_probability'] > 0.7].index\n",
    "    if len(high_risk_indices) > 0:\n",
    "        high_risk_profiles = X.iloc[high_risk_indices]\n",
    "        low_risk_indices = agent_risk[agent_risk['nill_probability'] < 0.3].index\n",
    "        low_risk_profiles = X.iloc[low_risk_indices]\n",
    "        \n",
    "        # Compare high vs low risk agents\n",
    "        print(\"\\nProfile Comparison - High Risk vs. Low Risk Agents:\")\n",
    "        comparison_cols = ['unique_proposal', 'unique_quotations', 'unique_customers', \n",
    "                          'activity_trend_score', 'agent_experience_months']\n",
    "        \n",
    "        high_risk_stats = high_risk_profiles[comparison_cols].mean()\n",
    "        low_risk_stats = low_risk_profiles[comparison_cols].mean()\n",
    "        \n",
    "        comparison = pd.DataFrame({\n",
    "            'High Risk': high_risk_stats,\n",
    "            'Low Risk': low_risk_stats,\n",
    "            'Difference %': ((low_risk_stats - high_risk_stats) / low_risk_stats * 100)\n",
    "        })\n",
    "        \n",
    "        print(comparison)\n",
    "        \n",
    "        # Generate recommendations based on characteristic differences\n",
    "        print(\"\\nRecommended Interventions for High-Risk Agents:\")\n",
    "        print(\"1. Increase proposal generation activity by at least 30%\")\n",
    "        print(\"2. Focus on improving proposal-to-quotation conversion rate through training\")\n",
    "        print(\"3. Implement weekly check-ins with mentors for agents with <6 months experience\")\n",
    "        print(\"4. Provide additional sales training focused on closing techniques\")\n",
    "        print(\"5. Set up peer shadowing with medium or high performing agents\")\n",
    "    \n",
    "    # Performance trajectory analysis\n",
    "    print(\"\\nPerformance Trajectory Analysis:\")\n",
    "    # Group agents by their performance trend (improving, stable, declining)\n",
    "    if 'agent_code' in train_data.columns and 'year_month' in train_data.columns and 'new_policy_count' in train_data.columns:\n",
    "        # Example trajectory analysis for a sample of agents\n",
    "        sample_agents = train_data['agent_code'].unique()[:5]\n",
    "        for agent in sample_agents:\n",
    "            agent_data = train_data[train_data['agent_code'] == agent].sort_values('year_month')\n",
    "            if len(agent_data) > 1:\n",
    "                first_month = agent_data['new_policy_count'].iloc[0]\n",
    "                last_month = agent_data['new_policy_count'].iloc[-1]\n",
    "                trend = \"Improving\" if last_month > first_month else \"Declining\" if last_month < first_month else \"Stable\"\n",
    "                print(f\"Agent {agent}: {trend} trend - Started with {first_month} policies, ended with {last_month} policies\")\n",
    "\n",
    "print(\"\\nModel Development Complete! Final submission saved as 'submission3.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd4274-b464-4730-a8ef-1bbdfc4c99cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65099c80-2cde-4a88-ab34-d3894ad4cf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
