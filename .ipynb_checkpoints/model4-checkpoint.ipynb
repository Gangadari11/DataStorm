{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ed03c8-8fab-4b90-a7bb-a5e4c3ce6d39",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3680441514.py, line 289)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 289\u001b[1;36m\u001b[0m\n\u001b[1;33m    use_label_encoder=False\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_recall_curve, auc, precision_score, recall_score, f1_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better visualization\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('train_storming_round.csv')\n",
    "test_data = pd.read_csv('test_storming_round.csv')\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# Examine the date format\n",
    "print(\"\\nSample of year_month values:\")\n",
    "print(train_data['year_month'].head())\n",
    "print(\"\\nSample of agent_join_month values:\")\n",
    "print(train_data['agent_join_month'].head())\n",
    "print(\"\\nSample of first_policy_sold_month values:\")\n",
    "print(train_data['first_policy_sold_month'].head())\n",
    "\n",
    "# Create target column based on new_policy_count\n",
    "# If new_policy_count is 0, target is 0 (NILL agent), otherwise 1\n",
    "train_data['target_column'] = (train_data['new_policy_count'] > 0).astype(int)\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution in training data:\")\n",
    "print(train_data['target_column'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# ---------------------- EDA PART ---------------------- #\n",
    "print(\"\\n========== EXPLORATORY DATA ANALYSIS ==========\")\n",
    "\n",
    "# 1. Summary Statistics\n",
    "print(\"\\n1. Key Metrics and Distributions (Summary Statistics):\")\n",
    "numeric_cols = train_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "summary_stats = train_data[numeric_cols].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = train_data.isnull().sum()\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(missing_values[missing_values > 0] if any(missing_values > 0) else \"No missing values found\")\n",
    "\n",
    "# 2. Sales Patterns by Month\n",
    "print(\"\\n2. Sales Patterns by Month:\")\n",
    "# Convert year_month to datetime for better analysis - using flexible parsing\n",
    "train_data['year_month'] = pd.to_datetime(train_data['year_month'], format='mixed', dayfirst=False)\n",
    "monthly_sales = train_data.groupby('year_month')['new_policy_count'].agg(['sum', 'mean', 'median'])\n",
    "print(monthly_sales.head())\n",
    "\n",
    "# Visualize monthly sales trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_sales['sum'].plot(marker='o')\n",
    "plt.title('Total Monthly Sales Over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Policies Sold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Multivariate Analysis\n",
    "print(\"\\n3. Multivariate Analysis:\")\n",
    "# Correlation matrix for numerical features\n",
    "correlation_matrix = train_data[numeric_cols].corr()\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with new_policy_count\n",
    "top_correlations = correlation_matrix['new_policy_count'].sort_values(ascending=False)\n",
    "print(\"Top correlations with new_policy_count:\")\n",
    "print(top_correlations)\n",
    "\n",
    "# 4. Agent Trajectories\n",
    "print(\"\\n4. Agent Trajectories Over Time:\")\n",
    "# Select a sample of agents to visualize\n",
    "sample_agents = train_data['agent_code'].unique()[:5]\n",
    "agent_data = train_data[train_data['agent_code'].isin(sample_agents)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for agent in sample_agents:\n",
    "    agent_history = agent_data[agent_data['agent_code'] == agent]\n",
    "    agent_history = agent_history.sort_values('year_month')\n",
    "    plt.plot(agent_history['year_month'], agent_history['new_policy_count'], marker='o', label=f'Agent {agent}')\n",
    "\n",
    "plt.title('Policy Sales Trajectories for Sample Agents')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Policies Sold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Innovative EDA\n",
    "print(\"\\n5. Innovative EDA - Additional Insights:\")\n",
    "\n",
    "# 5.1 Analyze the relationship between agent age and performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='target_column', y='agent_age', data=train_data)\n",
    "plt.title('Agent Age vs Performance')\n",
    "plt.xlabel('Performance (0=NILL, 1=Performing)')\n",
    "plt.ylabel('Agent Age')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.2 Analyze the impact of agent tenure on performance\n",
    "# Convert agent_join_month to datetime using flexible parsing\n",
    "train_data['agent_join_month'] = pd.to_datetime(train_data['agent_join_month'], format='mixed', dayfirst=False)\n",
    "train_data['tenure_months'] = (train_data['year_month'] - train_data['agent_join_month']).dt.days / 30\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='target_column', y='tenure_months', data=train_data)\n",
    "plt.title('Agent Tenure vs Performance')\n",
    "plt.xlabel('Performance (0=NILL, 1=Performing)')\n",
    "plt.ylabel('Tenure (Months)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.3 Analyze the relationship between proposal activity and sales\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(train_data['unique_proposal'], train_data['new_policy_count'], alpha=0.5)\n",
    "plt.title('Relationship Between Proposals and Sales')\n",
    "plt.xlabel('Number of Unique Proposals')\n",
    "plt.ylabel('Number of Policies Sold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5.4 Conversion rates analysis\n",
    "train_data['proposal_to_policy_ratio'] = train_data['new_policy_count'] / train_data['unique_proposal'].replace(0, np.nan)\n",
    "train_data['quotation_to_policy_ratio'] = train_data['new_policy_count'] / train_data['unique_quotations'].replace(0, np.nan)\n",
    "\n",
    "conversion_by_performance = train_data.groupby('target_column')[['proposal_to_policy_ratio', 'quotation_to_policy_ratio']].mean()\n",
    "print(\"\\nAverage Conversion Rates by Performance:\")\n",
    "print(conversion_by_performance)\n",
    "\n",
    "# ---------------------- FEATURE ENGINEERING ---------------------- #\n",
    "print(\"\\n========== FEATURE ENGINEERING ==========\")\n",
    "\n",
    "# Function to prepare features for both train and test data\n",
    "def prepare_features(data):\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Convert date columns to datetime using flexible parsing\n",
    "    df['year_month'] = pd.to_datetime(df['year_month'], format='mixed', dayfirst=False)\n",
    "    df['agent_join_month'] = pd.to_datetime(df['agent_join_month'], format='mixed', dayfirst=False)\n",
    "    \n",
    "    # Handle first_policy_sold_month (might be missing for agents who haven't sold yet)\n",
    "    df['first_policy_sold_month'] = pd.to_datetime(df['first_policy_sold_month'], format='mixed', errors='coerce', dayfirst=False)\n",
    "    \n",
    "    # Calculate tenure features\n",
    "    df['tenure_months'] = (df['year_month'] - df['agent_join_month']).dt.days / 30\n",
    "    \n",
    "    # Calculate time to first sale (for agents who have sold)\n",
    "    df['months_to_first_sale'] = np.where(\n",
    "        df['first_policy_sold_month'].notna(),\n",
    "        (df['first_policy_sold_month'] - df['agent_join_month']).dt.days / 30,\n",
    "        df['tenure_months']  # For agents who haven't sold, use tenure as a proxy\n",
    "    )\n",
    "    \n",
    "    # Extract month and year as separate features\n",
    "    df['month'] = df['year_month'].dt.month\n",
    "    df['year'] = df['year_month'].dt.year\n",
    "    \n",
    "    # Create activity ratios\n",
    "    df['proposal_per_customer'] = df['unique_proposal'] / df['unique_customers'].replace(0, 1)\n",
    "    df['quotation_per_proposal'] = df['unique_quotations'] / df['unique_proposal'].replace(0, 1)\n",
    "    \n",
    "    # Create recency features (activity in last 7 days as a proportion of total)\n",
    "    df['recent_proposal_ratio'] = df['unique_proposals_last_7_days'] / df['unique_proposal'].replace(0, 1)\n",
    "    df['recent_quotation_ratio'] = df['unique_quotations_last_7_days'] / df['unique_quotations'].replace(0, 1)\n",
    "    df['recent_customer_ratio'] = df['unique_customers_last_7_days'] / df['unique_customers'].replace(0, 1)\n",
    "    \n",
    "    # Create trend features (comparing recent activity to less recent)\n",
    "    df['proposal_trend'] = df['unique_proposals_last_7_days'] - df['unique_proposals_last_15_days']\n",
    "    df['quotation_trend'] = df['unique_quotations_last_7_days'] - df['unique_quotations_last_15_days']\n",
    "    df['customer_trend'] = df['unique_customers_last_7_days'] - df['unique_customers_last_15_days']\n",
    "    \n",
    "    # Average premium per policy\n",
    "    df['avg_premium_per_policy'] = df['ANBP_value'] / df['new_policy_count'].replace(0, np.nan)\n",
    "    \n",
    "    # Average income per policy\n",
    "    df['avg_income_per_policy'] = df['net_income'] / df['new_policy_count'].replace(0, np.nan)\n",
    "    \n",
    "    # Cash payment preference\n",
    "    df['cash_payment_ratio'] = df['number_of_cash_payment_policies'] / df['number_of_policy_holders'].replace(0, 1)\n",
    "    \n",
    "    # Drop original date columns and other unnecessary columns\n",
    "    cols_to_drop = ['year_month', 'agent_join_month', 'first_policy_sold_month']\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Identify numeric and non-numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "    \n",
    "    # Fill NaN values for numeric columns with median\n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    # Handle non-numeric columns - for categorical columns, fill with mode\n",
    "    for col in non_numeric_cols:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Prepare features for train and test data\n",
    "train_processed = prepare_features(train_data)\n",
    "test_processed = prepare_features(test_data)\n",
    "\n",
    "print(\"Processed train data shape:\", train_processed.shape)\n",
    "print(\"Processed test data columns:\", train_processed.columns.tolist())\n",
    "\n",
    "# ---------------------- MODEL BUILDING ---------------------- #\n",
    "print(\"\\n========== MODEL BUILDING ==========\")\n",
    "\n",
    "# Define features and target\n",
    "# Drop non-numeric columns that can't be used in the model\n",
    "X = train_processed.drop(['target_column', 'row_id', 'agent_code'], axis=1, errors='ignore')\n",
    "\n",
    "# Check for any remaining non-numeric columns\n",
    "non_numeric_cols = X.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"Removing non-numeric columns: {non_numeric_cols.tolist()}\")\n",
    "    X = X.drop(columns=non_numeric_cols)\n",
    "\n",
    "y = train_processed['target_column']\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Class distribution in training set: {pd.Series(y_train).value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Handle class imbalance using SMOTE and RandomUnderSampler in a pipeline\n",
    "# This creates a more balanced dataset by oversampling the minority class and undersampling the majority class\n",
    "sampling_strategy = 0.5  # Aim for a 1:2 ratio of minority to majority class\n",
    "over = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "steps = [('over', over), ('under', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Apply the resampling pipeline\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Resampled training set shape: {X_resampled.shape}\")\n",
    "print(f\"Class distribution after resampling: {pd.Series(y_resampled).value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Define XGBoost model with parameters to handle class imbalance\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    scale_pos_weight=sum(y_train == 0) / sum(y_train == 1),  # Weight for imbalanced classes\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    min_child_weight=2,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(\n",
    "    X_resampled_scaled, \n",
    "    y_resampled,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_proba = xgb_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Precision-Recall Curve (better for imbalanced datasets)\n",
    "precision, recall, _ = precision_recall_curve(y_val, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, marker='.', label=f'XGBoost (PR AUC = {pr_auc:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx])\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X.columns)[sorted_idx])\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "feature_imp_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(feature_imp_df.head(10))\n",
    "\n",
    "# ---------------------- HYPERPARAMETER TUNING ---------------------- #\n",
    "print(\"\\n========== HYPERPARAMETER TUNING ==========\")\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'scale_pos_weight': [1, 3, 5]  # Different weights for handling class imbalance\n",
    "}\n",
    "\n",
    "# Use a smaller grid for demonstration purposes\n",
    "small_param_grid = {\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'scale_pos_weight': [1, 5]\n",
    "}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ),\n",
    "    param_grid=small_param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "print(\"Running grid search (this may take some time)...\")\n",
    "grid_search.fit(X_resampled_scaled, y_resampled)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best ROC AUC score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    **grid_search.best_params_,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    X_resampled_scaled, \n",
    "    y_resampled,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Final evaluation\n",
    "y_pred_proba_best = best_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_pred_best = (y_pred_proba_best >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nFinal Model Evaluation:\")\n",
    "print(classification_report(y_val, y_pred_best))\n",
    "\n",
    "# ROC AUC for best model\n",
    "roc_auc_best = roc_auc_score(y_val, y_pred_proba_best)\n",
    "print(f\"Final ROC AUC Score: {roc_auc_best:.4f}\")\n",
    "\n",
    "# Precision-Recall AUC for best model\n",
    "precision_best, recall_best, _ = precision_recall_curve(y_val, y_pred_proba_best)\n",
    "pr_auc_best = auc(recall_best, precision_best)\n",
    "print(f\"Final Precision-Recall AUC: {pr_auc_best:.4f}\")\n",
    "\n",
    "# ---------------------- PREDICTION ON TEST DATA ---------------------- #\n",
    "print(\"\\n========== PREDICTION ON TEST DATA ==========\")\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test_processed.drop(['row_id', 'agent_code'], axis=1, errors='ignore')\n",
    "\n",
    "# Check for any remaining non-numeric columns in test data\n",
    "non_numeric_cols_test = X_test.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "if len(non_numeric_cols_test) > 0:\n",
    "    print(f\"Removing non-numeric columns from test data: {non_numeric_cols_test.tolist()}\")\n",
    "    X_test = X_test.drop(columns=non_numeric_cols_test)\n",
    "\n",
    "# Make sure test data has the same columns as training data\n",
    "missing_cols = set(X.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0  # Add missing columns with default value\n",
    "\n",
    "# Ensure columns are in the same order\n",
    "X_test = X_test[X.columns]\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "test_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "test_pred = (test_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': test_data['row_id'],\n",
    "    'target_column': test_pred\n",
    "})\n",
    "\n",
    "print(\"Sample of predictions:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('xgboost_submission4.csv', index=False)\n",
    "print(\"Submission file saved as 'xgboost_submission.csv'\")\n",
    "\n",
    "# ---------------------- INSIGHTS AND RECOMMENDATIONS ---------------------- #\n",
    "print(\"\\n========== INSIGHTS AND RECOMMENDATIONS ==========\")\n",
    "\n",
    "# Key factors influencing agent performance\n",
    "print(\"\\nKey Factors Influencing Agent Performance:\")\n",
    "for i, (feature, importance) in enumerate(zip(feature_imp_df['Feature'].head(10), \n",
    "                                             feature_imp_df['Importance'].head(10))):\n",
    "    print(f\"{i+1}. {feature}: {importance:.4f}\")\n",
    "\n",
    "# Personalized action plans based on risk levels\n",
    "print(\"\\nPersonalized SMART Action Plans for At-Risk Agents:\")\n",
    "\n",
    "print(\"\\n1. High-Risk Agents (Probability of NILL > 0.75):\")\n",
    "print(\"   - Immediate intervention with daily check-ins and mentoring\")\n",
    "print(\"   - Focused training on proposal-to-sale conversion techniques\")\n",
    "print(\"   - Set daily activity targets for customer contacts and proposals\")\n",
    "print(\"   - Pair with a high-performing agent for shadowing\")\n",
    "print(\"   - Weekly performance review with branch manager\")\n",
    "\n",
    "print(\"\\n2. Medium-Risk Agents (Probability of NILL 0.5-0.75):\")\n",
    "print(\"   - Bi-weekly check-ins with team leader\")\n",
    "print(\"   - Targeted training on specific weak areas identified by the model\")\n",
    "print(\"   - Increase activity in high-converting customer segments\")\n",
    "print(\"   - Set weekly goals for proposal and quotation activities\")\n",
    "print(\"   - Provide additional marketing support and lead generation\")\n",
    "\n",
    "print(\"\\n3. Low-Risk Agents (Probability of NILL < 0.5):\")\n",
    "print(\"   - Monthly performance review\")\n",
    "print(\"   - Continuous learning opportunities\")\n",
    "print(\"   - Focus on upselling and cross-selling to existing customers\")\n",
    "print(\"   - Incentivize maintaining consistent activity levels\")\n",
    "print(\"   - Recognize and reward positive performance trends\")\n",
    "\n",
    "# Monitoring framework\n",
    "print(\"\\nMonitoring Framework for Intervention Effectiveness:\")\n",
    "print(\"1. Track weekly changes in key performance indicators\")\n",
    "print(\"2. Compare pre and post-intervention performance metrics\")\n",
    "print(\"3. Measure changes in model-predicted risk scores over time\")\n",
    "print(\"4. Conduct A/B testing of different intervention strategies\")\n",
    "print(\"5. Establish feedback loops with agents and managers\")\n",
    "\n",
    "# ---------------------- THRESHOLD OPTIMIZATION ---------------------- #\n",
    "print(\"\\n========== THRESHOLD OPTIMIZATION ==========\")\n",
    "\n",
    "# Find the optimal threshold for classification\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_proba_best >= threshold).astype(int)\n",
    "    precision = precision_score(y_val, y_pred_threshold)\n",
    "    recall = recall_score(y_val, y_pred_threshold)\n",
    "    f1 = f1_score(y_val, y_pred_threshold)\n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(thresholds, precision_scores, 'b-', label='Precision')\n",
    "plt.plot(thresholds, recall_scores, 'g-', label='Recall')\n",
    "plt.plot(thresholds, f1_scores, 'r-', label='F1 Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall and F1 Score as a Function of Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the threshold that maximizes F1 score\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"Precision at optimal threshold: {precision_scores[optimal_idx]:.4f}\")\n",
    "print(f\"Recall at optimal threshold: {recall_scores[optimal_idx]:.4f}\")\n",
    "print(f\"F1 Score at optimal threshold: {f1_scores[optimal_idx]:.4f}\")\n",
    "\n",
    "# Apply the optimal threshold to the test predictions\n",
    "optimized_test_pred = (test_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Create optimized submission file\n",
    "optimized_submission = pd.DataFrame({\n",
    "    'row_id': test_data['row_id'],\n",
    "    'target_column': optimized_test_pred\n",
    "})\n",
    "\n",
    "print(\"Sample of optimized predictions:\")\n",
    "print(optimized_submission.head())\n",
    "\n",
    "# Save optimized submission file\n",
    "optimized_submission.to_csv('xgboost_optimized_submission4.csv', index=False)\n",
    "print(\"Optimized submission file saved as 'xgboost_optimized_submission.csv'\")\n",
    "\n",
    "# ---------------------- FEATURE SELECTION ---------------------- #\n",
    "print(\"\\n========== FEATURE SELECTION ==========\")\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Use the trained XGBoost model for feature selection\n",
    "selection = SelectFromModel(best_model, threshold='median', prefit=True)\n",
    "X_selected = selection.transform(X_resampled_scaled)\n",
    "selected_feature_indices = selection.get_support()\n",
    "selected_features = X.columns[selected_feature_indices].tolist()\n",
    "\n",
    "print(f\"Number of features selected: {len(selected_features)} out of {X.shape[1]}\")\n",
    "print(\"Selected features:\")\n",
    "for i, feature in enumerate(selected_features):\n",
    "    print(f\"{i+1}. {feature}\")\n",
    "\n",
    "# Train a model with selected features\n",
    "X_val_selected = selection.transform(X_val_scaled)\n",
    "X_test_selected = selection.transform(X_test_scaled)\n",
    "\n",
    "# Train model with selected features\n",
    "selected_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    **grid_search.best_params_,\n",
    "    early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "selected_model.fit(\n",
    "    X_selected, \n",
    "    y_resampled,\n",
    "    eval_set=[(X_val_selected, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluate model with selected features\n",
    "y_pred_proba_selected = selected_model.predict_proba(X_val_selected)[:, 1]\n",
    "y_pred_selected = (y_pred_proba_selected >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nModel Evaluation with Selected Features:\")\n",
    "print(classification_report(y_val, y_pred_selected))\n",
    "\n",
    "# ROC AUC for selected features model\n",
    "roc_auc_selected = roc_auc_score(y_val, y_pred_proba_selected)\n",
    "print(f\"ROC AUC Score with Selected Features: {roc_auc_selected:.4f}\")\n",
    "\n",
    "# Compare with full model\n",
    "print(\"\\nComparison with Full Model:\")\n",
    "print(f\"Full Model ROC AUC: {roc_auc_best:.4f}\")\n",
    "print(f\"Selected Features Model ROC AUC: {roc_auc_selected:.4f}\")\n",
    "print(f\"Difference: {roc_auc_selected - roc_auc_best:.4f}\")\n",
    "\n",
    "# Make predictions with selected features model\n",
    "test_pred_proba_selected = selected_model.predict_proba(X_test_selected)[:, 1]\n",
    "test_pred_selected = (test_pred_proba_selected >= optimal_threshold).astype(int)\n",
    "\n",
    "# Create submission file with selected features model\n",
    "selected_submission = pd.DataFrame({\n",
    "    'row_id': test_data['row_id'],\n",
    "    'target_column': test_pred_selected\n",
    "})\n",
    "\n",
    "print(\"Sample of predictions with selected features:\")\n",
    "print(selected_submission.head())\n",
    "\n",
    "# Save submission file with selected features\n",
    "selected_submission.to_csv('xgboost_selected_features_submission4.csv', index=False)\n",
    "print(\"Selected features submission file saved as 'xgboost_selected_features_submission.csv'\")\n",
    "\n",
    "# ---------------------- AGENT SEGMENTATION ---------------------- #\n",
    "print(\"\\n========== AGENT SEGMENTATION ==========\")\n",
    "\n",
    "# Create a DataFrame with agent codes and their predicted probabilities\n",
    "agent_predictions = pd.DataFrame({\n",
    "    'agent_code': test_data['agent_code'],\n",
    "    'nill_probability': test_pred_proba\n",
    "})\n",
    "\n",
    "# Define risk segments\n",
    "agent_predictions['risk_segment'] = pd.cut(\n",
    "    agent_predictions['nill_probability'], \n",
    "    bins=[0, 0.25, 0.5, 0.75, 1.0], \n",
    "    labels=['Low Risk', 'Medium-Low Risk', 'Medium-High Risk', 'High Risk']\n",
    ")\n",
    "\n",
    "# Count agents in each segment\n",
    "segment_counts = agent_predictions['risk_segment'].value_counts().sort_index()\n",
    "print(\"Agent Risk Segmentation:\")\n",
    "print(segment_counts)\n",
    "\n",
    "# Visualize the segmentation\n",
    "plt.figure(figsize=(10, 6))\n",
    "segment_counts.plot(kind='bar', color=['green', 'yellow', 'orange', 'red'])\n",
    "plt.title('Agent Risk Segmentation')\n",
    "plt.xlabel('Risk Segment')\n",
    "plt.ylabel('Number of Agents')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create personalized recommendations for each segment\n",
    "print(\"\\nPersonalized Recommendations by Risk Segment:\")\n",
    "\n",
    "print(\"\\nHigh Risk Agents (Probability of NILL > 0.75):\")\n",
    "print(\"1. Immediate intervention with daily check-ins and mentoring\")\n",
    "print(\"2. Focused training on proposal-to-sale conversion techniques\")\n",
    "print(\"3. Set daily activity targets for customer contacts and proposals\")\n",
    "print(\"4. Pair with a high-performing agent for shadowing\")\n",
    "print(\"5. Weekly performance review with branch manager\")\n",
    "\n",
    "print(\"\\nMedium-High Risk Agents (Probability of NILL 0.5-0.75):\")\n",
    "print(\"1. Bi-weekly check-ins with team leader\")\n",
    "print(\"2. Targeted training on specific weak areas identified by the model\")\n",
    "print(\"3. Increase activity in high-converting customer segments\")\n",
    "print(\"4. Set weekly goals for proposal and quotation activities\")\n",
    "print(\"5. Provide additional marketing support and lead generation\")\n",
    "\n",
    "print(\"\\nMedium-Low Risk Agents (Probability of NILL 0.25-0.5):\")\n",
    "print(\"1. Monthly check-ins with team leader\")\n",
    "print(\"2. Focus on improving conversion rates\")\n",
    "print(\"3. Encourage peer learning and knowledge sharing\")\n",
    "print(\"4. Set bi-weekly goals for customer engagement\")\n",
    "print(\"5. Provide access to additional training resources\")\n",
    "\n",
    "print(\"\\nLow Risk Agents (Probability of NILL < 0.25):\")\n",
    "print(\"1. Quarterly performance review\")\n",
    "print(\"2. Continuous learning opportunities\")\n",
    "print(\"3. Focus on upselling and cross-selling to existing customers\")\n",
    "print(\"4. Incentivize maintaining consistent activity levels\")\n",
    "print(\"5. Recognize and reward positive performance trends\")\n",
    "\n",
    "# Analyze feature importance by segment\n",
    "print(\"\\nKey Factors by Risk Segment:\")\n",
    "\n",
    "# Get top 5 features for each segment\n",
    "top_features = feature_imp_df['Feature'].head(5).tolist()\n",
    "print(f\"Top 5 features across all segments: {top_features}\")\n",
    "\n",
    "# ---------------------- CROSS-VALIDATION ANALYSIS ---------------------- #\n",
    "print(\"\\n========== CROSS-VALIDATION ANALYSIS ==========\")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# Define the model with best parameters\n",
    "cv_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    **grid_search.best_params_\n",
    ")\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(\n",
    "    cv_model, \n",
    "    X_resampled_scaled, \n",
    "    y_resampled, \n",
    "    cv=cv, \n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "for metric in scoring.keys():\n",
    "    train_scores = cv_results[f'train_{metric}']\n",
    "    test_scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric.upper()}:\")\n",
    "    print(f\"  Train: {train_scores.mean():.4f} ± {train_scores.std():.4f}\")\n",
    "    print(f\"  Test:  {test_scores.mean():.4f} ± {test_scores.std():.4f}\")\n",
    "    print(f\"  Difference: {train_scores.mean() - test_scores.mean():.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize cross-validation results\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics = list(scoring.keys())\n",
    "train_means = [cv_results[f'train_{metric}'].mean() for metric in metrics]\n",
    "test_means = [cv_results[f'test_{metric}'].mean() for metric in metrics]\n",
    "train_stds = [cv_results[f'train_{metric}'].std() for metric in metrics]\n",
    "test_stds = [cv_results[f'test_{metric}'].std() for metric in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_means, width, label='Train', color='skyblue', yerr=train_stds)\n",
    "plt.bar(x + width/2, test_means, width, label='Test', color='lightcoral', yerr=test_stds)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Cross-Validation Results')\n",
    "plt.xticks(x, [m.upper() for m in metrics])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for overfitting\n",
    "overfitting = [train_means[i] - test_means[i] for i in range(len(metrics))]\n",
    "print(\"\\nOverfitting Analysis:\")\n",
    "for i, metric in enumerate(metrics):\n",
    "    print(f\"{metric.upper()} overfitting: {overfitting[i]:.4f}\")\n",
    "\n",
    "# ---------------------- CONCLUSION ---------------------- #\n",
    "print(\"\\n========== CONCLUSION ==========\")\n",
    "\n",
    "print(\"\\nSummary of XGBoost Model for NILL Agent Prediction:\")\n",
    "print(\"1. The model successfully predicts agents at risk of becoming NILL agents\")\n",
    "print(\"2. Class imbalance was addressed using SMOTE, RandomUnderSampler, and scale_pos_weight\")\n",
    "print(\"3. Feature engineering created meaningful predictors from raw data\")\n",
    "print(\"4. Threshold optimization improved model performance for the imbalanced dataset\")\n",
    "print(\"5. Feature selection identified the most important predictors\")\n",
    "print(\"6. Agent segmentation provides actionable insights for targeted interventions\")\n",
    "print(\"7. Cross-validation confirms model robustness and generalizability\")\n",
    "\n",
    "print(\"\\nKey Recommendations:\")\n",
    "print(\"1. Implement the risk-based segmentation approach for agent management\")\n",
    "print(\"2. Focus interventions on the high and medium-high risk segments\")\n",
    "print(\"3. Monitor key performance indicators identified by feature importance\")\n",
    "print(\"4. Establish a feedback loop to continuously improve the model\")\n",
    "print(\"5. Deploy the model in production for real-time risk assessment\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Integrate the model into the agent management system\")\n",
    "print(\"2. Develop a dashboard for monitoring agent risk scores\")\n",
    "print(\"3. Implement A/B testing of intervention strategies\")\n",
    "print(\"4. Collect feedback from field managers on model effectiveness\")\n",
    "print(\"5. Retrain the model periodically with new data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef02702-d6e1-458d-94ee-27a97b4415dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
