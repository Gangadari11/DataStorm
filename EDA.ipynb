{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255b642c-b268-4e9a-a869-65f4b08a200d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2315378397.py, line 939)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 939\u001b[1;36m\u001b[0m\n\u001b[1;33m    'unique_customers_last_15_days', 'unique_customers_last_21_days', 'unique_customers',\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Insurance Agent Performance EDA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Read the training data\n",
    "train_df = pd.read_csv('train_stroming_round.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", train_df.shape)\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "display(train_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "# Create the target column as specified in the instructions\n",
    "train_df['target'] = (train_df['new_policy_count'] > 0).astype(int)\n",
    "print(\"\\nTarget distribution (0 = NILL, 1 = Active):\")\n",
    "print(train_df['target'].value_counts())\n",
    "print(f\"Percentage of NILL agents: {(1 - train_df['target'].mean()) * 100:.2f}%\")\n",
    "\n",
    "# Convert date columns to datetime\n",
    "date_columns = ['agent_join_month', 'first_policy_sold_month', 'year_month']\n",
    "for col in date_columns:\n",
    "    train_df[col] = pd.to_datetime(train_df[col])\n",
    "\n",
    "# Extract additional temporal features\n",
    "train_df['agent_tenure_months'] = ((train_df['year_month'].dt.year - train_df['agent_join_month'].dt.year) * 12 + \n",
    "                                  (train_df['year_month'].dt.month - train_df['agent_join_month'].dt.month))\n",
    "\n",
    "train_df['months_since_first_sale'] = ((train_df['year_month'].dt.year - train_df['first_policy_sold_month'].dt.year) * 12 + \n",
    "                                      (train_df['year_month'].dt.month - train_df['first_policy_sold_month'].dt.month))\n",
    "\n",
    "# Replace infinite values with NaN and then fill with 0\n",
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_df['months_since_first_sale'].fillna(0, inplace=True)\n",
    "\n",
    "# Add year and month columns for easier analysis\n",
    "train_df['year'] = train_df['year_month'].dt.year\n",
    "train_df['month'] = train_df['year_month'].dt.month\n",
    "\n",
    "# Create conversion ratios\n",
    "train_df['proposal_to_quotation_ratio'] = train_df['unique_quotations'] / train_df['unique_proposal'].replace(0, 1)\n",
    "train_df['quotation_to_policy_ratio'] = train_df['new_policy_count'] / train_df['unique_quotations'].replace(0, 1)\n",
    "train_df['proposal_to_policy_ratio'] = train_df['new_policy_count'] / train_df['unique_proposal'].replace(0, 1)\n",
    "train_df['cash_payment_ratio'] = train_df['number_of_cash_payment_policies'] / train_df['number_of_policy_holders'].replace(0, 1)\n",
    "train_df['avg_premium_per_policy'] = train_df['ANBP_value'] / train_df['new_policy_count'].replace(0, 1)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 1. KEY METRICS AND DISTRIBUTIONS (SUMMARY STATISTICS)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n========== 1. KEY METRICS AND DISTRIBUTIONS ==========\")\n",
    "\n",
    "# Get summary statistics for numerical columns\n",
    "numerical_cols = train_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"\\nSummary statistics for numerical features:\")\n",
    "display(train_df[numerical_cols].describe())\n",
    "\n",
    "# Plot distributions of key performance metrics\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Create a list of key performance metrics\n",
    "key_metrics = ['new_policy_count', 'ANBP_value', 'net_income', 'number_of_policy_holders',\n",
    "               'unique_proposal', 'unique_quotations', 'unique_customers']\n",
    "\n",
    "for i, metric in enumerate(key_metrics):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    \n",
    "    # Plot histogram with KDE\n",
    "    sns.histplot(train_df[metric], kde=True)\n",
    "    \n",
    "    # Add median line\n",
    "    median_val = train_df[metric].median()\n",
    "    plt.axvline(median_val, color='red', linestyle='--', \n",
    "                label=f'Median: {median_val:.2f}')\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = train_df[metric].mean()\n",
    "    plt.axvline(mean_val, color='green', linestyle='-', \n",
    "                label=f'Mean: {mean_val:.2f}')\n",
    "    \n",
    "    plt.title(f'Distribution of {metric}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('key_metrics_distributions.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot distributions by target\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "for i, metric in enumerate(key_metrics):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    \n",
    "    sns.kdeplot(data=train_df, x=metric, hue='target', common_norm=False, fill=True)\n",
    "    \n",
    "    plt.title(f'Distribution of {metric} by Target')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('key_metrics_by_target.png')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation_matrix = train_df[numerical_cols].corr()\n",
    "mask = np.triu(correlation_matrix)\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            mask=mask, linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of agent ages\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=train_df, x='agent_age', hue='target', kde=True, element='step')\n",
    "plt.title('Distribution of Agent Ages by Target')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('agent_age_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of agent tenure\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=train_df, x='agent_tenure_months', hue='target', kde=True, element='step')\n",
    "plt.title('Distribution of Agent Tenure by Target')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('agent_tenure_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of conversion ratios\n",
    "plt.figure(figsize=(16, 10))\n",
    "conversion_ratios = ['proposal_to_quotation_ratio', 'quotation_to_policy_ratio', \n",
    "                    'proposal_to_policy_ratio', 'cash_payment_ratio']\n",
    "\n",
    "for i, ratio in enumerate(conversion_ratios):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.histplot(data=train_df, x=ratio, hue='target', kde=True, element='step')\n",
    "    plt.title(f'Distribution of {ratio} by Target')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('conversion_ratios.png')\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 2. SALES PATTERNS BY MONTH AND TIME SERIES ANALYSIS\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n========== 2. SALES PATTERNS BY MONTH ==========\")\n",
    "\n",
    "# Aggregate data by month\n",
    "monthly_stats = train_df.groupby('year_month').agg({\n",
    "    'new_policy_count': 'mean',\n",
    "    'ANBP_value': 'mean',\n",
    "    'net_income': 'mean',\n",
    "    'target': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_stats['nill_rate'] = 1 - monthly_stats['target']\n",
    "\n",
    "# Plot time series of key metrics\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# New policy count over time\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(monthly_stats['year_month'], monthly_stats['new_policy_count'], marker='o')\n",
    "plt.title('Average New Policy Count Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ANBP value over time\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(monthly_stats['year_month'], monthly_stats['ANBP_value'], marker='o')\n",
    "plt.title('Average ANBP Value Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Net income over time\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(monthly_stats['year_month'], monthly_stats['net_income'], marker='o')\n",
    "plt.title('Average Net Income Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# NILL rate over time\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(monthly_stats['year_month'], monthly_stats['nill_rate'], marker='o')\n",
    "plt.title('NILL Rate Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('time_series_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "# Seasonal decomposition\n",
    "# First, let's check if we have enough data for seasonal decomposition\n",
    "print(\"\\nUnique year-month combinations:\", train_df['year_month'].nunique())\n",
    "unique_months = sorted(train_df['year_month'].unique())\n",
    "print(\"Date range:\", min(unique_months), \"to\", max(unique_months))\n",
    "\n",
    "# Let's analyze seasonal patterns by month\n",
    "monthly_patterns = train_df.groupby('month').agg({\n",
    "    'new_policy_count': 'mean',\n",
    "    'ANBP_value': 'mean',\n",
    "    'net_income': 'mean',\n",
    "    'target': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_patterns['nill_rate'] = 1 - monthly_patterns['target']\n",
    "\n",
    "# Plot monthly patterns\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "metrics = ['new_policy_count', 'ANBP_value', 'net_income', 'nill_rate']\n",
    "titles = ['Average New Policy Count', 'Average ANBP Value', 'Average Net Income', 'NILL Rate']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.bar(monthly_patterns['month'], monthly_patterns[metric])\n",
    "    plt.title(f'{title} by Month')\n",
    "    plt.xlabel('Month')\n",
    "    plt.xticks(range(1, 13))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('monthly_patterns.png')\n",
    "plt.show()\n",
    "\n",
    "# Check for anomalies in the time series\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=('Avg New Policy Count', 'Avg ANBP Value', \n",
    "                                                  'Avg Net Income', 'NILL Rate'))\n",
    "\n",
    "metrics = ['new_policy_count', 'ANBP_value', 'net_income', 'nill_rate']\n",
    "row_col_pairs = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "\n",
    "for (metric, (row, col)) in zip(metrics, row_col_pairs):\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_val = monthly_stats[metric].mean()\n",
    "    std_val = monthly_stats[metric].std()\n",
    "    \n",
    "    # Define anomaly thresholds (2 standard deviations from mean)\n",
    "    upper_bound = mean_val + 2 * std_val\n",
    "    lower_bound = mean_val - 2 * std_val\n",
    "    \n",
    "    # Identify anomalies\n",
    "    anomalies = monthly_stats[\n",
    "        (monthly_stats[metric] > upper_bound) | \n",
    "        (monthly_stats[metric] < lower_bound)\n",
    "    ]\n",
    "    \n",
    "    # Add time series trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=monthly_stats['year_month'], \n",
    "            y=monthly_stats[metric],\n",
    "            mode='lines+markers',\n",
    "            name=metric\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    # Add anomaly points\n",
    "    if not anomalies.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=anomalies['year_month'],\n",
    "                y=anomalies[metric],\n",
    "                mode='markers',\n",
    "                marker=dict(size=10, color='red'),\n",
    "                name=f'{metric} anomalies'\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Add threshold lines\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=min(monthly_stats['year_month']),\n",
    "        y0=upper_bound,\n",
    "        x1=max(monthly_stats['year_month']),\n",
    "        y1=upper_bound,\n",
    "        line=dict(color=\"red\", width=1, dash=\"dash\"),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=min(monthly_stats['year_month']),\n",
    "        y0=lower_bound,\n",
    "        x1=max(monthly_stats['year_month']),\n",
    "        y1=lower_bound,\n",
    "        line=dict(color=\"red\", width=1, dash=\"dash\"),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=800, width=1200, title_text=\"Time Series Analysis with Anomaly Detection\",\n",
    "                 showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 3. MULTIVARIATE ANALYSIS\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n========== 3. MULTIVARIATE ANALYSIS ==========\")\n",
    "\n",
    "# Select numerical features for multivariate analysis\n",
    "num_features = ['agent_age', 'agent_tenure_months', 'unique_proposal', 'unique_quotations', \n",
    "               'unique_customers', 'new_policy_count', 'ANBP_value', 'net_income',\n",
    "               'number_of_policy_holders', 'number_of_cash_payment_policies']\n",
    "\n",
    "# Pairplot of key features colored by target\n",
    "print(\"Generating pairplot of key features...\")\n",
    "sns.pairplot(train_df[num_features[:6] + ['target']], hue='target', height=2.5, \n",
    "             plot_kws={'alpha': 0.5, 's': 20})\n",
    "plt.suptitle('Pairplot of Key Features', y=1.02)\n",
    "plt.savefig('pairplot.png')\n",
    "plt.show()\n",
    "\n",
    "# Principal Component Analysis (PCA) for dimensionality reduction\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Prepare data for PCA\n",
    "X = train_df[num_features].copy()\n",
    "X = X.fillna(X.mean())  # Handle any remaining missing values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': pca_result[:, 0],\n",
    "    'PC2': pca_result[:, 1],\n",
    "    'PC3': pca_result[:, 2],\n",
    "    'target': train_df['target']\n",
    "})\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# 3D PCA Plot\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "scatter = ax.scatter(\n",
    "    pca_df['PC1'], \n",
    "    pca_df['PC2'], \n",
    "    pca_df['PC3'],\n",
    "    c=pca_df['target'],\n",
    "    cmap='viridis',\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('3D PCA of Numerical Features')\n",
    "\n",
    "# Add a color bar\n",
    "plt.colorbar(scatter, ax=ax, label='Target (0=NILL, 1=Active)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_3d.png')\n",
    "plt.show()\n",
    "\n",
    "# Display explained variance\n",
    "print(\"\\nPCA Explained Variance Ratio:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(f\"Total Explained Variance (3 components): {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# Feature importance in each principal component\n",
    "pca_components = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=['PC1', 'PC2', 'PC3'],\n",
    "    index=num_features\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(pca_components, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('PCA Components Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_components.png')\n",
    "plt.show()\n",
    "\n",
    "# Interactive 3D scatter plot with Plotly\n",
    "fig = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='target',\n",
    "    opacity=0.7,\n",
    "    title='3D PCA - NILL vs Active Agents'\n",
    ")\n",
    "fig.update_layout(height=800, width=1000)\n",
    "fig.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 4. AGENT TRAJECTORIES OVER TIME\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n========== 4. AGENT TRAJECTORIES OVER TIME ==========\")\n",
    "\n",
    "# Select a random sample of agents for trajectory analysis\n",
    "sample_agents = train_df['agent_code'].unique()[:20]\n",
    "\n",
    "# Filter data for the sampled agents\n",
    "agent_trajectories = train_df[train_df['agent_code'].isin(sample_agents)]\n",
    "\n",
    "# Plot agent performance over time\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# New policy count trajectories\n",
    "plt.subplot(2, 2, 1)\n",
    "for agent in sample_agents:\n",
    "    agent_data = agent_trajectories[agent_trajectories['agent_code'] == agent]\n",
    "    if not agent_data.empty:\n",
    "        plt.plot(agent_data['year_month'], agent_data['new_policy_count'], marker='o', label=f'Agent {agent}')\n",
    "plt.title('New Policy Count Trajectories')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ANBP value trajectories\n",
    "plt.subplot(2, 2, 2)\n",
    "for agent in sample_agents:\n",
    "    agent_data = agent_trajectories[agent_trajectories['agent_code'] == agent]\n",
    "    if not agent_data.empty:\n",
    "        plt.plot(agent_data['year_month'], agent_data['ANBP_value'], marker='o', label=f'Agent {agent}')\n",
    "plt.title('ANBP Value Trajectories')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Net income trajectories\n",
    "plt.subplot(2, 2, 3)\n",
    "for agent in sample_agents:\n",
    "    agent_data = agent_trajectories[agent_trajectories['agent_code'] == agent]\n",
    "    if not agent_data.empty:\n",
    "        plt.plot(agent_data['year_month'], agent_data['net_income'], marker='o', label=f'Agent {agent}')\n",
    "plt.title('Net Income Trajectories')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Target trajectories (NILL vs Active)\n",
    "plt.subplot(2, 2, 4)\n",
    "for agent in sample_agents:\n",
    "    agent_data = agent_trajectories[agent_trajectories['agent_code'] == agent]\n",
    "    if not agent_data.empty:\n",
    "        plt.plot(agent_data['year_month'], agent_data['target'], marker='o', label=f'Agent {agent}')\n",
    "plt.title('Target Status Trajectories (0=NILL, 1=Active)')\n",
    "plt.yticks([0, 1])\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('agent_trajectories.png')\n",
    "plt.show()\n",
    "\n",
    "# Analyze the first few months of agent performance\n",
    "early_performance = train_df.copy()\n",
    "\n",
    "# Get the first few months (up to 3) for each agent\n",
    "early_performance['months_active'] = early_performance.groupby('agent_code')['year_month'].rank()\n",
    "early_months = early_performance[early_performance['months_active'] <= 3]\n",
    "\n",
    "# Calculate average performance in early months\n",
    "early_avg_performance = early_months.groupby('agent_code').agg({\n",
    "    'new_policy_count': 'mean',\n",
    "    'ANBP_value': 'mean',\n",
    "    'net_income': 'mean',\n",
    "    'target': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "early_avg_performance['early_nill_rate'] = 1 - early_avg_performance['target']\n",
    "\n",
    "# Get the latest performance status for each agent\n",
    "latest_performance = train_df.sort_values(['agent_code', 'year_month']).groupby('agent_code').last().reset_index()\n",
    "\n",
    "# Merge early and latest performance\n",
    "performance_trajectory = pd.merge(early_avg_performance, latest_performance[['agent_code', 'target']], \n",
    "                                 on='agent_code', suffixes=('_early', '_latest'))\n",
    "\n",
    "# Calculate transition probabilities\n",
    "print(\"\\nTransition Probabilities from Early Performance to Latest Status:\")\n",
    "transition_counts = performance_trajectory.groupby(['target_early', 'target_latest']).size().unstack(fill_value=0)\n",
    "transition_probs = transition_counts.div(transition_counts.sum(axis=1), axis=0)\n",
    "print(transition_probs)\n",
    "\n",
    "# Plot relationship between early performance and latest status\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "metrics = ['new_policy_count', 'ANBP_value', 'net_income', 'early_nill_rate']\n",
    "titles = ['Avg New Policy Count in First 3 Months', 'Avg ANBP Value in First 3 Months',\n",
    "         'Avg Net Income in First 3 Months', 'NILL Rate in First 3 Months']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(x='target_latest', y=metric, data=performance_trajectory)\n",
    "    plt.title(f'{title} vs Latest Status')\n",
    "    plt.xlabel('Latest Status (0=NILL, 1=Active)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('early_vs_latest_performance.png')\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# 5. INNOVATIVE EDA - HIDDEN INSIGHTS\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n========== 5. INNOVATIVE EDA - HIDDEN INSIGHTS ==========\")\n",
    "\n",
    "# 1. Analyze the impact of the gap between joining and first sale\n",
    "train_df['days_to_first_sale'] = (train_df['first_policy_sold_month'] - train_df['agent_join_month']).dt.days\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='target', y='days_to_first_sale', data=train_df)\n",
    "plt.title('Days to First Sale vs Target')\n",
    "plt.xlabel('Target (0=NILL, 1=Active)')\n",
    "plt.ylabel('Days to First Sale')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('days_to_first_sale.png')\n",
    "plt.show()\n",
    "\n",
    "# 2. Analyze activity patterns (proposals, quotations, customers) as predictors of NILL\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "activity_metrics = [\n",
    "    'unique_proposals_last_7_days', 'unique_proposals_last_15_days', 'unique_proposals_last_21_days',\n",
    "    'unique_quotations_last_7_days', 'unique_quotations_last_15_days', 'unique_quotations_last_21_days',\n",
    "    'unique_customers_last_7_days', 'unique_customers_last_15_days', 'unique_customers_last_21_days'\n",
    "]\n",
    "\n",
    "for i, metric in enumerate(activity_metrics):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.boxplot(x='target', y=metric, data=train_df)\n",
    "    plt.title(f'{metric} vs Target')\n",
    "    plt.xlabel('Target (0=NILL, 1=Active)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activity_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "# 3. Calculate the decay in activity over time windows\n",
    "train_df['proposal_decay_7_to_15'] = train_df['unique_proposals_last_7_days'] - train_df['unique_proposals_last_15_days']\n",
    "train_df['proposal_decay_15_to_21'] = train_df['unique_proposals_last_15_days'] - train_df['unique_proposals_last_21_days']\n",
    "train_df['quotation_decay_7_to_15'] = train_df['unique_quotations_last_7_days'] - train_df['unique_quotations_last_15_days']\n",
    "train_df['quotation_decay_15_to_21'] = train_df['unique_quotations_last_15_days'] - train_df['unique_quotations_last_21_days']\n",
    "train_df['customer_decay_7_to_15'] = train_df['unique_customers_last_7_days'] - train_df['unique_customers_last_15_days']\n",
    "train_df['customer_decay_15_to_21'] = train_df['unique_customers_last_15_days'] - train_df['unique_customers_last_21_days']\n",
    "\n",
    "decay_metrics = [\n",
    "    'proposal_decay_7_to_15', 'proposal_decay_15_to_21',\n",
    "    'quotation_decay_7_to_15', 'quotation_decay_15_to_21',\n",
    "    'customer_decay_7_to_15', 'customer_decay_15_to_21'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, metric in enumerate(decay_metrics):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x='target', y=metric, data=train_df)\n",
    "    plt.title(f'{metric} vs Target')\n",
    "    plt.xlabel('Target (0=NILL, 1=Active)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activity_decay.png')\n",
    "plt.show()\n",
    "\n",
    "# 4. Agent age group analysis\n",
    "train_df['age_group'] = pd.cut(train_df['agent_age'], bins=[20, 30, 40, 50, 60, 100], \n",
    "                              labels=['20-30', '30-40', '40-50', '50-60', '60+'])\n",
    "\n",
    "age_group_stats = train_df.groupby('age_group').agg({\n",
    "    'new_policy_count': 'mean',\n",
    "    'ANBP_value': 'mean',\n",
    "    'net_income': 'mean',\n",
    "    'target': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "age_group_stats['nill_rate'] = 1 - age_group_stats['target']\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "metrics = ['new_policy_count', 'ANBP_value', 'net_income', 'nill_rate']\n",
    "titles = ['Avg New Policy Count', 'Avg ANBP Value', 'Avg Net Income', 'NILL Rate']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.bar(age_group_stats['age_group'], age_group_stats[metric])\n",
    "    plt.title(f'{title} by Age Group')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('age_group_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "# 5. Performance decay analysis - how performance changes over an agent's tenure\n",
    "performance_by_tenure = train_df.groupby('agent_tenure_months').agg({\n",
    "    'new_policy_count': 'mean',\n",
    "    'ANBP_value': 'mean',\n",
    "    'net_income': 'mean',\n",
    "    'target': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "performance_by_tenure['nill_rate'] = 1 - performance_by_tenure['target']\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(performance_by_tenure['agent_tenure_months'], performance_by_tenure[metric], marker='o')\n",
    "    plt.title(f'{title} by Tenure Months')\n",
    "    plt.xlabel('Tenure (Months)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_by_tenure.png')\n",
    "plt.show()\n",
    "\n",
    "# 6. Cash payment preferences analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(\n",
    "    data=train_df,\n",
    "    x='number_of_policy_holders',\n",
    "    y='number_of_cash_payment_policies',\n",
    "    hue='target',\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.title('Cash Payment Policies vs Total Policy Holders')\n",
    "plt.xlabel('Number of Policy Holders')\n",
    "plt.ylabel('Number of Cash Payment Policies')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('cash_payment_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "# 7. Feature importance for target prediction using a simple model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare features\n",
    "features = [\n",
    "    'agent_age', 'agent_tenure_months', 'days_to_first_sale', 'months_since_first_sale',\n",
    "    'unique_proposals_last_7_days', 'unique_proposals_last_15_days', 'unique_proposals_last_21_days',\n",
    "    'unique_proposal', 'unique_quotations_last_7_days', 'unique_quotations_last_15_days',\n",
    "    'unique_quotations_last_21_days', 'unique_quotations', 'unique_customers_last_7_days',\n",
    "    'unique_customers_last_15_days', 'unique_customers_last_21_days', 'unique_customers',\n",
    "    'proposal_decay_7_to_15', 'proposal_decay_15_to_21', 'quotation_decay_7_to_15', \n",
    "    'quotation_decay_15_to_21', 'customer_decay_7_to_15', 'customer_decay_15_to_21',\n",
    "    'proposal_to_quotation_ratio', 'quotation_to_policy_ratio', 'proposal_to_policy_ratio',\n",
    "    'cash_payment_ratio']\n",
    "\n",
    "# Fill missing values with medians\n",
    "X = train_df[features].copy()\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Create target variable\n",
    "y = train_df['target'].copy()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a simple model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_proba = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Model AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf.feature_importances_\n",
    "})\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances.head(15))\n",
    "plt.title('Top 15 Important Features for Predicting NILL Agents')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "# 8. Survival analysis - time to first NILL status\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Create a new dataframe for survival analysis\n",
    "# We need to identify when an agent first becomes NILL\n",
    "agent_survival = train_df.sort_values(['agent_code', 'year_month']).copy()\n",
    "agent_survival['is_nill'] = 1 - agent_survival['target']\n",
    "agent_survival['first_nill'] = agent_survival.groupby('agent_code')['is_nill'].cumsum() > 0\n",
    "agent_survival['time_to_first_nill'] = agent_survival.groupby('agent_code')['year_month'].rank()\n",
    "\n",
    "# Get the first occurrence of NILL for each agent\n",
    "first_nill_events = agent_survival[agent_survival['first_nill'] & (agent_survival['is_nill'] == 1)].groupby('agent_code').first().reset_index()\n",
    "first_nill_events['event'] = 1  # NILL occurred\n",
    "\n",
    "# Get agents who never became NILL\n",
    "never_nill_agents = set(agent_survival['agent_code'].unique()) - set(first_nill_events['agent_code'].unique())\n",
    "never_nill_data = agent_survival[agent_survival['agent_code'].isin(never_nill_agents)].groupby('agent_code').last().reset_index()\n",
    "never_nill_data['event'] = 0  # NILL never occurred (censored)\n",
    "\n",
    "# Combine data\n",
    "survival_data = pd.concat([\n",
    "    first_nill_events[['agent_code', 'time_to_first_nill', 'event', 'agent_age']],\n",
    "    never_nill_data[['agent_code', 'time_to_first_nill', 'event', 'agent_age']]\n",
    "])\n",
    "\n",
    "# Fit Kaplan-Meier model\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(survival_data['time_to_first_nill'], event_observed=survival_data['event'])\n",
    "\n",
    "# Plot survival curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "kmf.plot_survival_function()\n",
    "plt.title('Survival Curve - Time to First NILL Status')\n",
    "plt.xlabel('Months Active')\n",
    "plt.ylabel('Probability of Still Being Active')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('survival_curve.png')\n",
    "plt.show()\n",
    "\n",
    "# Split by age group\n",
    "survival_data['age_group'] = pd.cut(survival_data['agent_age'], bins=[20, 30, 40, 50, 60, 100], \n",
    "                                   labels=['20-30', '30-40', '40-50', '50-60', '60+'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for age_group in survival_data['age_group'].unique():\n",
    "    if pd.isna(age_group):\n",
    "        continue\n",
    "    kmf = KaplanMeierFitter()\n",
    "    mask = survival_data['age_group'] == age_group\n",
    "    if mask.sum() > 5:  # Only plot if we have enough data\n",
    "        kmf.fit(survival_data[mask]['time_to_first_nill'], event_observed=survival_data[mask]['event'], label=age_group)\n",
    "        kmf.plot_survival_function()\n",
    "        \n",
    "plt.title('Survival Curves by Age Group - Time to First NILL Status')\n",
    "plt.xlabel('Months Active')\n",
    "plt.ylabel('Probability of Still Being Active')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('survival_curve_by_age.png')\n",
    "plt.show()\n",
    "\n",
    "# 9. Funnel analysis - Conversion through the sales process\n",
    "funnel_stages = ['unique_proposal', 'unique_quotations', 'new_policy_count']\n",
    "funnel_data = train_df[funnel_stages].mean().reset_index()\n",
    "funnel_data.columns = ['Stage', 'Average']\n",
    "funnel_data['Stage'] = ['Proposals', 'Quotations', 'Policies']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(funnel_data['Stage'], funnel_data['Average'])\n",
    "plt.title('Sales Funnel - Average per Agent')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('sales_funnel.png')\n",
    "plt.show()\n",
    "\n",
    "# Calculate conversion rates between funnel stages\n",
    "print(\"\\nFunnel Conversion Rates:\")\n",
    "print(f\"Proposal to Quotation: {(train_df['unique_quotations'].mean() / train_df['unique_proposal'].mean()) * 100:.2f}%\")\n",
    "print(f\"Quotation to Policy: {(train_df['new_policy_count'].mean() / train_df['unique_quotations'].mean()) * 100:.2f}%\")\n",
    "print(f\"Overall (Proposal to Policy): {(train_df['new_policy_count'].mean() / train_df['unique_proposal'].mean()) * 100:.2f}%\")\n",
    "\n",
    "# Compare funnel conversion rates between NILL and Active agents\n",
    "nill_funnel = train_df[train_df['target'] == 0][funnel_stages].mean()\n",
    "active_funnel = train_df[train_df['target'] == 1][funnel_stages].mean()\n",
    "\n",
    "conversion_comparison = pd.DataFrame({\n",
    "    'NILL Agents': nill_funnel,\n",
    "    'Active Agents': active_funnel\n",
    "}).reset_index()\n",
    "conversion_comparison.columns = ['Stage', 'NILL Agents', 'Active Agents']\n",
    "conversion_comparison['Stage'] = ['Proposals', 'Quotations', 'Policies']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(conversion_comparison['Stage']))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, conversion_comparison['NILL Agents'], width, label='NILL Agents')\n",
    "plt.bar(x + width/2, conversion_comparison['Active Agents'], width, label='Active Agents')\n",
    "\n",
    "plt.title('Sales Funnel Comparison - NILL vs Active Agents')\n",
    "plt.xticks(x, conversion_comparison['Stage'])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('funnel_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# 10. Clustering agents based on their behavior\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select features for clustering\n",
    "cluster_features = [\n",
    "    'agent_age', 'agent_tenure_months',\n",
    "    'unique_proposal', 'unique_quotations', 'unique_customers',\n",
    "    'proposal_to_quotation_ratio', 'quotation_to_policy_ratio'\n",
    "]\n",
    "\n",
    "# Prepare data\n",
    "X_cluster = train_df[cluster_features].copy()\n",
    "X_cluster = X_cluster.fillna(X_cluster.median())\n",
    "X_cluster_scaled = StandardScaler().fit_transform(X_cluster)\n",
    "\n",
    "# Determine optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "k_range = range(2, 11)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('elbow_method.png')\n",
    "plt.show()\n",
    "\n",
    "# Choose the number of clusters based on the elbow method\n",
    "n_clusters = 4  # Adjust based on the elbow plot\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "train_df['cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "cluster_stats = train_df.groupby('cluster').agg({\n",
    "    'agent_age': 'mean',\n",
    "    'agent_tenure_months': 'mean',\n",
    "    'unique_proposal': 'mean',\n",
    "    'unique_quotations': 'mean',\n",
    "    'unique_customers': 'mean',\n",
    "    'new_policy_count': 'mean',\n",
    "    'ANBP_value': 'mean',\n",
    "    'net_income': 'mean',\n",
    "    'target': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "cluster_stats['nill_rate'] = 1 - cluster_stats['target']\n",
    "\n",
    "# Display cluster statistics\n",
    "print(\"\\nCluster Characteristics:\")\n",
    "display(cluster_stats)\n",
    "\n",
    "# Plot key metrics by cluster\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "metrics = ['new_policy_count', 'ANBP_value', 'net_income', 'nill_rate']\n",
    "titles = ['Avg New Policy Count', 'Avg ANBP Value', 'Avg Net Income', 'NILL Rate']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.bar(cluster_stats['cluster'], cluster_stats[metric])\n",
    "    plt.title(f'{title} by Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "# Visualization of clusters in 2D space using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=train_df['cluster'], cmap='viridis', alpha=0.5)\n",
    "plt.title('Agent Clusters Visualized in 2D Space')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('cluster_visualization.png')\n",
    "plt.show()\n",
    "\n",
    "# Show NILL rate by cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "nill_by_cluster = train_df.groupby('cluster')['target'].mean().reset_index()\n",
    "nill_by_cluster['nill_rate'] = 1 - nill_by_cluster['target']\n",
    "plt.bar(nill_by_cluster['cluster'], nill_by_cluster['nill_rate'])\n",
    "plt.title('NILL Rate by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('NILL Rate')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('nill_rate_by_cluster.png')\n",
    "plt.show()\n",
    "\n",
    "# Print summary of insights\n",
    "print(\"\\n\\n========== SUMMARY OF KEY INSIGHTS ==========\")\n",
    "print(\"\\n1. The overall NILL rate in the dataset is {:.2f}%.\".format((1 - train_df['target'].mean()) * 100))\n",
    "print(\"\\n2. Key features that distinguish NILL agents from active agents include:\")\n",
    "for feature, importance in zip(feature_importances['Feature'].head(5), feature_importances['Importance'].head(5)):\n",
    "    print(f\"   - {feature}: {importance:.4f}\")\n",
    "print(\"\\n3. Agents typically have a higher risk of becoming NILL in their early months.\")\n",
    "print(\"\\n4. Time series analysis shows seasonal patterns in agent performance.\")\n",
    "print(\"\\n5. Agent activity metrics (proposals, quotations, customers) in the last 7, 15, and 21 days are strong predictors of NILL status.\")\n",
    "print(\"\\n6. The proposal-to-policy conversion ratio is a key indicator of agent success.\")\n",
    "print(\"\\n7. Clustering identified distinct agent profiles with varying NILL rates.\")\n",
    "print(\"\\n8. Agent age and tenure show significant correlations with performance and NILL risk.\")\n",
    "\n",
    "    'unique_customers_last_15_days', 'unique_customers_last_21_days', 'unique_customers',\n",
    "    'proposal_decay_7_to_15', 'proposal_decay_15_to_21', 'quotation_decay_7_to_15', \n",
    "    'quotation_decay_15_to_21', 'customer_decay_7_to_15', 'customer_decay_15_to_21',\n",
    "    'proposal_to_quotation_ratio', 'quotation_to_policy_ratio', 'proposal_to_policy_ratio',\n",
    "    'cash_payment_ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2c56b-15e5-4fc5-91ff-9c2c23009ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
